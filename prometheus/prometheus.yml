global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: [
        'prometheus:9090',
#               'localhost:9090',
#               '127.0.0.1:9090',
        'host.docker.internal:9090'
      ]

#  - job_name: 'backend'
#    static_configs:
#      - targets: [
#        'host.docker.internal:8080',
#        'localhost:8080 '
##        'backend:8080',
#      ]


  - job_name: 'node-exporter'
    static_configs:
      - targets: [
        'host.docker.internal:9100',
#        'localhost:9100'
        'node-exporter:9100'
      ]

  # job 기준으로 메트릭을 수집한다.
  - job_name: "spring-actuator" # job_name 은 모든 scrap 내에서 고유해야한다
    metrics_path: '/actuator/prometheus' # 스프링부트에서 설정한 endpoint [metrics_path의 기본 경로는 '/metrics'], 뒤에 prometheus를 붙이면 prometheus의 정보를 가져온다.
    scrape_interval: 15s # global 값과 다르게 사용할려면 따로 정의하자.
#    scheme: 'http' # request를 보낼 scheme 설정 [scheme의 기본값은 `http`]
    static_configs:
      - targets: [
#        'localhost:8080',
                  'host.docker.internal:8080']
    # request를 보낼 server ip 그리고 actuator port를 적어주면 된다. (위에서 지정한 포트는 9090이며, 서버 IP는 EC2의 Public Ip를 적어주자)
    # 보안을 위해서 JWT를 사용. (내 Spring 서버에서 사용할 수 있는 JWT를 발급받아서 사용)
#    bearer_token: 'JWT Token'

#  - job_name: 'nginx'
#    scrape_interval: 10s
#    static_configs:
#      - targets: ['nginxexporter:9113']

